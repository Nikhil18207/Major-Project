{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XR2Text: Model Training with HAQT-ARR\n",
    "\n",
    "## IMPROVED VERSION - Optimized for RTX 4060 8GB\n",
    "\n",
    "**Authors**: S. Nikhil, Dadhania Omkumar  \n",
    "**Supervisor**: Dr. Damodar Panigrahy\n",
    "\n",
    "---\n",
    "\n",
    "This notebook implements the complete training pipeline for XR2Text:\n",
    "\n",
    "### Architecture (NOVEL CONTRIBUTIONS):\n",
    "1. **HAQT-ARR** - Hierarchical Anatomical Query Tokens with Adaptive Region Routing\n",
    "2. **Uncertainty Quantification** - MC Dropout + Temperature Calibration\n",
    "3. **Factual Grounding** - Knowledge Graph + Hallucination Detection\n",
    "4. **Multi-Task Learning** - Region/Severity/Finding Classification\n",
    "\n",
    "### Training Configuration:\n",
    "- **BioBART-Large** decoder (upgraded from base)\n",
    "- **Gradient Accumulation**: 128 steps (~240 steps/epoch)\n",
    "- **Curriculum Learning**: 5 stages over 50 epochs\n",
    "- **Gradient Checkpointing** for RTX 4060 memory efficiency\n",
    "- **Estimated Time**: ~65 hours (~2.7 days)\n",
    "\n",
    "### Expected Results:\n",
    "| Metric | Target | SOTA Reference |\n",
    "|--------|--------|----------------|\n",
    "| BLEU-4 | 0.12+ | 0.142 (ChestBioX-Gen) |\n",
    "| ROUGE-L | 0.28+ | 0.312 (ChestBioX-Gen) |\n",
    "| Clinical F1 | 0.70+ | Novel metric |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MajorProject\\swin\\lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SYSTEM CONFIGURATION\n",
      "==================================================\n",
      "CUDA Available: True\n",
      "GPU Connected: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU Memory: 8.0 GB\n",
      "CUDA Version: 12.1\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "\n",
      "Using Device: cuda\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GPU/CUDA Check - Run this first!\n",
    "# ============================================\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "# GPU Check\n",
    "print(\"=\" * 50)\n",
    "print(\"SYSTEM CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"CUDA Available: True\")\n",
    "    print(f\"GPU Connected: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(f\"CUDA Available: False\")\n",
    "    print(f\"WARNING: Running on CPU (Training will be slow)\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"\\nUsing Device: {device}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "XR2Text Training Config - RTX 4060 OPTIMIZED\n",
      "======================================================================\n",
      "\n",
      "  Epochs: 50\n",
      "  Gradient Accumulation: 128 (effective batch=128)\n",
      "  Steps per Epoch: ~240\n",
      "  Warmup Steps: 500\n",
      "\n",
      "CURRICULUM STAGES (5-stage, 50 epochs):\n",
      "  warmup:   0-5    (normal cases)\n",
      "  easy:     5-12   (≤2 findings)\n",
      "  medium:   12-25  (≤4 findings)\n",
      "  hard:     25-40  (all cases)\n",
      "  finetune: 40-50  (full dataset)\n",
      "\n",
      "ESTIMATED TIME: ~65 hours (~2.7 days)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration with HAQT-ARR + ALL NOVEL FEATURES (10/10 Novelty)\n",
    "# OPTIMIZED FOR RTX 4060 8GB - ~65 hours (2.7 days)\n",
    "config = {\n",
    "    # Model\n",
    "    'image_size': 384,\n",
    "    'encoder_name': 'base',  # Swin-Base\n",
    "    'decoder_name': 'biobart-large',  # UPGRADED: BioBART-Large for better generation\n",
    "    'use_anatomical_attention': True,  # Enable HAQT-ARR (Novel)\n",
    "    \n",
    "    # HAQT-ARR specific parameters (NOVEL)\n",
    "    'num_regions': 7,\n",
    "    'num_global_queries': 8,\n",
    "    'num_region_queries': 4,\n",
    "    'use_spatial_priors': True,\n",
    "    'use_adaptive_routing': True,\n",
    "    'use_cross_region': True,\n",
    "    \n",
    "    # NEW: Enhancement Modules (10/10 Novelty)\n",
    "    'use_uncertainty': True,           # Uncertainty quantification\n",
    "    'use_grounding': True,             # Factual grounding & hallucination detection\n",
    "    'use_explainability': True,        # Explainability & evidence regions\n",
    "    'use_multitask': True,             # Multi-task learning heads\n",
    "    \n",
    "    # Standard parameters\n",
    "    'language_dim': 1024,              # UPDATED: BioBART-Large uses 1024 hidden dim\n",
    "    \n",
    "    # Training - SPEED OPTIMIZED FOR 2.7 DAYS\n",
    "    'epochs': 50,                      # 50 epochs\n",
    "    'batch_size': 1,                   # Keep at 1 for memory\n",
    "    'gradient_accumulation_steps': 128, # ~240 steps/epoch, ~65 hours total (2.7 days)\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,              # FIXED: Match default.yaml\n",
    "    'warmup_steps': 500,               # Warmup steps\n",
    "    'max_grad_norm': 1.0,\n",
    "    \n",
    "    # Label smoothing - for better BLEU\n",
    "    'label_smoothing': 0.05,\n",
    "    \n",
    "    # NOVEL: Novel Loss Functions - ENABLED\n",
    "    'use_novel_losses': True,\n",
    "    'use_anatomical_consistency_loss': True,\n",
    "    'use_clinical_entity_loss': True,\n",
    "    'use_region_focal_loss': True,\n",
    "    'use_cross_modal_loss': True,\n",
    "    'anatomical_loss_weight': 0.1,\n",
    "    'clinical_loss_weight': 0.2,\n",
    "    'focal_loss_weight': 0.15,\n",
    "    'alignment_loss_weight': 0.1,\n",
    "    \n",
    "    # R-Drop Regularization - DISABLED for faster training\n",
    "    'use_rdrop': False,\n",
    "    'rdrop_alpha': 0.7,\n",
    "    \n",
    "    # NOVEL: Curriculum Learning - ENABLED (5 stages over 50 epochs)\n",
    "    'use_curriculum_learning': True,\n",
    "    \n",
    "    # NOVEL: Clinical Validation - ENABLED\n",
    "    'use_clinical_validation': True,\n",
    "    \n",
    "    # NEW: Uncertainty Quantification\n",
    "    'use_uncertainty_training': True,\n",
    "    'uncertainty_dropout': 0.1,\n",
    "    'mc_samples': 5,\n",
    "    'use_calibration': True,\n",
    "    \n",
    "    # NEW: Multi-Task Learning\n",
    "    'use_multi_task_learning': True,\n",
    "    'auxiliary_task_weights': {\n",
    "        'region_classification': 0.1,\n",
    "        'severity_prediction': 0.1,\n",
    "        'finding_detection': 0.15,\n",
    "        'length_prediction': 0.05,\n",
    "    },\n",
    "    \n",
    "    # NEW: Factual Grounding\n",
    "    'use_factual_grounding': True,\n",
    "    'grounding_loss_weight': 0.1,\n",
    "    'grounding_threshold': 0.15,\n",
    "    \n",
    "    # NEW: OOD Detection\n",
    "    'use_ood_detection': True,\n",
    "    'ood_threshold': 0.5,\n",
    "    \n",
    "    # Scheduled Sampling\n",
    "    'use_scheduled_sampling': True,\n",
    "    'scheduled_sampling_start': 1.0,\n",
    "    'scheduled_sampling_end': 0.4,\n",
    "    'scheduled_sampling_warmup': 10,\n",
    "    \n",
    "    # Region regularization\n",
    "    'use_region_regularization': True,\n",
    "    'region_regularization_weight': 0.01,\n",
    "    \n",
    "    # Data\n",
    "    'max_length': 256,\n",
    "    'num_workers': 2,\n",
    "    \n",
    "    # Device\n",
    "    'use_amp': True,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Experiment\n",
    "    'experiment_name': f'xr2text_haqt_arr_full_novel_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'checkpoint_dir': '../checkpoints',\n",
    "    'validate_every': 2,\n",
    "    'save_every': 1,                   # Save EVERY epoch\n",
    "    'patience': 20,\n",
    "    'log_dir': '../logs',\n",
    "    \n",
    "    # Validation - FAST\n",
    "    'val_fraction': 0.10,\n",
    "    \n",
    "    # Generation parameters - OPTIMIZED FOR SPEED\n",
    "    'generation': {\n",
    "        'num_beams': 2,\n",
    "        'min_length': 20,\n",
    "        'max_length': 200,\n",
    "        'length_penalty': 1.0,\n",
    "        'repetition_penalty': 1.3,\n",
    "        'no_repeat_ngram_size': 3,\n",
    "        'early_stopping': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(config['log_dir'], exist_ok=True)\n",
    "os.makedirs('../data/figures', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"XR2Text Training Config - RTX 4060 OPTIMIZED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n  Epochs: {config['epochs']}\")\n",
    "print(f\"  Gradient Accumulation: {config['gradient_accumulation_steps']} (effective batch=128)\")\n",
    "print(f\"  Steps per Epoch: ~240\")\n",
    "print(f\"  Warmup Steps: {config['warmup_steps']}\")\n",
    "print(\"\\nCURRICULUM STAGES (5-stage, 50 epochs):\")\n",
    "print(\"  warmup:   0-5    (normal cases)\")\n",
    "print(\"  easy:     5-12   (≤2 findings)\")\n",
    "print(\"  medium:   12-25  (≤4 findings)\")\n",
    "print(\"  hard:     25-40  (all cases)\")\n",
    "print(\"  finetune: 40-50  (full dataset)\")\n",
    "print(\"\\nESTIMATED TIME: ~65 hours (~2.7 days)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:19:46.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEnabled cuDNN benchmark mode\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:46.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mEnabled TF32 for matrix operations\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:46.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCleared CUDA cache\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:46.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mBuilding Swin Transformer Encoder...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:46.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.swin_encoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mInitializing Swin Encoder: swin_base_patch4_window7_224\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:46.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.swin_encoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mPretrained: True, Image Size: 384\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating XR2Text model with HAQT-ARR + Enhancement Modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:19:48.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.swin_encoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mSwin feature dimension: 1024\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.swin_encoder\u001b[0m:\u001b[36m_freeze_layers\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mFrozen 404,424 parameters in 2 layers\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.swin_encoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mSwin Encoder initialized successfully\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mBuilding HAQT-ARR (Hierarchical Anatomical) Projection Layer...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m799\u001b[0m - \u001b[1mInitializing HAQT-ARR Projection Layer\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m800\u001b[0m - \u001b[1m  Visual dim: 1024 -> Language dim: 1024\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m801\u001b[0m - \u001b[1m  Regions: 7, Total queries: 36\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m802\u001b[0m - \u001b[1m  Spatial priors: True, Adaptive routing: True\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m409\u001b[0m - \u001b[1mAnatomicalQueryTokens: 8 global + 7x4 region queries\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m238\u001b[0m - \u001b[1mImageConditionedSpatialPriorRefiner initialized for 7 regions\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m846\u001b[0m - \u001b[1m  Image-conditioned prior refinement: ENABLED\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.anatomical_attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m901\u001b[0m - \u001b[1mHAQT-ARR Projection Layer initialized successfully\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mBuilding BioBART Decoder...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.biobart_decoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mInitializing decoder: GanjinZero/biobart-large\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.biobart_decoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mLabel smoothing: 0.0\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:48.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.biobart_decoder\u001b[0m:\u001b[36m_init_bart_decoder\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mAttempting to load decoder: GanjinZero/biobart-large\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.biobart_decoder\u001b[0m:\u001b[36m_init_bart_decoder\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mSuccessfully loaded decoder: GanjinZero/biobart-large\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.biobart_decoder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mDecoder initialized with hidden_dim: 1024\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mBuilding Uncertainty Estimator...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.uncertainty_estimator\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m562\u001b[0m - \u001b[1mUncertaintyEstimator initialized with 10 MC samples\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mBuilding Factual Grounding Module...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.knowledge_grounding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mMedicalKnowledgeGraph initialized with 24 findings\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.knowledge_grounding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mFactualGroundingModule initialized with 24 findings\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mBuilding Explainability Module...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.explainability\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mExplainabilityModule initialized\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mBuilding Multi-Task Learning Head...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.auxiliary_tasks\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mMultiTaskHead initialized: regions=7, findings=20, severity_classes=4\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mXR2Text Model initialized successfully!\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m_log_model_info\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1mTotal parameters: 541,634,767\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m_log_model_info\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTrainable parameters: 541,230,343\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:53.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.xr2text\u001b[0m:\u001b[36m_log_model_info\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mFrozen parameters: 404,424\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "XR2Text Model with HAQT-ARR + Enhancement Modules (10/10 Novelty)\n",
      "============================================================\n",
      "Total parameters: 541,634,767\n",
      "Trainable parameters: 541,230,343\n",
      "Frozen parameters: 404,424\n",
      "\n",
      "Anatomical regions: ['right_lung', 'left_lung', 'heart', 'mediastinum', 'spine', 'diaphragm', 'costophrenic_angles']\n",
      "Total queries: 36\n",
      "\n",
      "Enhancement Modules Enabled:\n",
      "  - Uncertainty Quantification: True\n",
      "  - Factual Grounding: True\n",
      "  - Explainability: True\n",
      "  - Multi-Task Learning: True\n"
     ]
    }
   ],
   "source": [
    "from src.models.xr2text import XR2TextModel, DEFAULT_CONFIG\n",
    "from src.models.anatomical_attention import ANATOMICAL_REGIONS\n",
    "from src.data.dataloader import get_dataloaders\n",
    "from src.utils.device import setup_cuda_optimizations\n",
    "\n",
    "# Setup CUDA optimizations for RTX 4060\n",
    "setup_cuda_optimizations()\n",
    "\n",
    "# Create model with HAQT-ARR + ALL ENHANCEMENT MODULES (10/10 Novelty)\n",
    "print(\"Creating XR2Text model with HAQT-ARR + Enhancement Modules...\")\n",
    "model_config = {\n",
    "    'image_size': config['image_size'],\n",
    "    'use_anatomical_attention': config['use_anatomical_attention'],  # Enable HAQT-ARR\n",
    "    \n",
    "    # NEW: Enhancement Modules (10/10 Novelty)\n",
    "    'use_uncertainty': config.get('use_uncertainty', True),\n",
    "    'use_grounding': config.get('use_grounding', True),\n",
    "    'use_explainability': config.get('use_explainability', True),\n",
    "    'use_multitask': config.get('use_multitask', True),\n",
    "    \n",
    "    'encoder': {\n",
    "        'model_name': config['encoder_name'],\n",
    "        'pretrained': True,\n",
    "        'freeze_layers': 2,  # Freeze first 2 Swin layers\n",
    "    },\n",
    "    'projection': {\n",
    "        # HAQT-ARR parameters (Novel)\n",
    "        'language_dim': config['language_dim'],\n",
    "        'num_regions': config['num_regions'],\n",
    "        'num_global_queries': config['num_global_queries'],\n",
    "        'num_region_queries': config['num_region_queries'],\n",
    "        'use_spatial_priors': config['use_spatial_priors'],\n",
    "        'use_adaptive_routing': config['use_adaptive_routing'],\n",
    "        'use_cross_region': config['use_cross_region'],\n",
    "        'feature_size': 12,  # 384/32 = 12x12 patches\n",
    "    },\n",
    "    'decoder': {\n",
    "        'model_name': config['decoder_name'],\n",
    "        'max_length': config['max_length'],\n",
    "    }\n",
    "}\n",
    "\n",
    "model = XR2TextModel.from_config(model_config)\n",
    "model = model.to(config['device'])\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"XR2Text Model with HAQT-ARR + Enhancement Modules (10/10 Novelty)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"\\nAnatomical regions: {model.get_anatomical_regions()}\")\n",
    "print(f\"Total queries: {config['num_global_queries'] + config['num_regions'] * config['num_region_queries']}\")\n",
    "print(f\"\\nEnhancement Modules Enabled:\")\n",
    "print(f\"  - Uncertainty Quantification: {config.get('use_uncertainty', True)}\")\n",
    "print(f\"  - Factual Grounding: {config.get('use_grounding', True)}\")\n",
    "print(f\"  - Explainability: {config.get('use_explainability', True)}\")\n",
    "print(f\"  - Multi-Task Learning: {config.get('use_multitask', True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:19:54.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mCreating dataloaders...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:54.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading MIMIC-CXR dataset (split: train)...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:19:59.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mLoaded 30633 samples\u001b[0m\n",
      "\u001b[32m2026-01-15 20:19:59.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading MIMIC-CXR dataset (split: validation)...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:00.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mLoaded 3063 samples\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:00.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading MIMIC-CXR dataset (split: test)...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mLoaded 3064 samples\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mTrain samples: 30633\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mVal samples: 3063\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTest samples: 3064\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mBatch size: 1\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:02.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataloader\u001b[0m:\u001b[36mget_dataloaders\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mTrain batches: 30633\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 30633\n",
      "Val batches: 3063\n",
      "Test batches: 3064\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"\\nLoading datasets...\")\n",
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    image_size=config['image_size'],\n",
    "    max_length=config['max_length'],\n",
    "    train_subset=None,  # Use full dataset, or set to e.g., 1000 for testing\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Novel loss functions initialized\n",
      "✅ Curriculum learning scheduler initialized\n",
      "✅ Clinical validator initialized\n",
      "\n",
      "Total optimization steps: 11966\n",
      "Warmup steps: 500\n",
      "Novel losses: True\n",
      "Curriculum learning: True\n",
      "Clinical validation: True\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from src.training.scheduler import get_cosine_schedule_with_warmup\n",
    "from src.utils.metrics import compute_metrics\n",
    "\n",
    "# NOVEL: Import novel training components\n",
    "from src.training.losses import CombinedNovelLoss\n",
    "from src.training.curriculum import AnatomicalCurriculumScheduler, create_curriculum_dataloader\n",
    "from src.utils.clinical_validator import ClinicalValidator\n",
    "\n",
    "# Optimizer\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'layer_norm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if p.requires_grad and not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config['weight_decay'],\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if p.requires_grad and any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=config['learning_rate'])\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * config['epochs'] // config['gradient_accumulation_steps']\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config['warmup_steps'],\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler() if config['use_amp'] else None\n",
    "\n",
    "# NOVEL: Initialize novel loss functions\n",
    "if config.get('use_novel_losses', False):\n",
    "    novel_loss = CombinedNovelLoss(\n",
    "        use_anatomical_consistency=config.get('use_anatomical_consistency_loss', True),\n",
    "        use_clinical_entity=config.get('use_clinical_entity_loss', True),\n",
    "        use_region_focal=config.get('use_region_focal_loss', True),\n",
    "        use_cross_modal=config.get('use_cross_modal_loss', False),\n",
    "        anatomical_weight=config.get('anatomical_loss_weight', 0.1),\n",
    "        clinical_weight=config.get('clinical_loss_weight', 0.2),\n",
    "        focal_weight=config.get('focal_loss_weight', 0.15),\n",
    "        alignment_weight=config.get('alignment_loss_weight', 0.1),\n",
    "    )\n",
    "    print(\"✅ Novel loss functions initialized\")\n",
    "else:\n",
    "    novel_loss = None\n",
    "\n",
    "# NOVEL: Initialize curriculum learning scheduler\n",
    "if config.get('use_curriculum_learning', False):\n",
    "    curriculum_scheduler = AnatomicalCurriculumScheduler()\n",
    "    print(\"✅ Curriculum learning scheduler initialized\")\n",
    "else:\n",
    "    curriculum_scheduler = None\n",
    "\n",
    "# NOVEL: Initialize clinical validator\n",
    "if config.get('use_clinical_validation', False):\n",
    "    clinical_validator = ClinicalValidator()\n",
    "    print(\"✅ Clinical validator initialized\")\n",
    "else:\n",
    "    clinical_validator = None\n",
    "\n",
    "print(f\"\\nTotal optimization steps: {total_steps}\")\n",
    "print(f\"Warmup steps: {config['warmup_steps']}\")\n",
    "print(f\"Novel losses: {config.get('use_novel_losses', False)}\")\n",
    "print(f\"Curriculum learning: {config.get('use_curriculum_learning', False)}\")\n",
    "print(f\"Clinical validation: {config.get('use_clinical_validation', False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'bleu_1': [],\n",
    "    'bleu_2': [],\n",
    "    'bleu_3': [],\n",
    "    'bleu_4': [],\n",
    "    'rouge_1': [],\n",
    "    'rouge_2': [],\n",
    "    'rouge_l': [],\n",
    "    'learning_rate': [],\n",
    "}\n",
    "\n",
    "best_metric = 0.0\n",
    "patience_counter = 0\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:20:09.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36mget_device\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mUsing CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEnabled cuDNN benchmark mode\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mEnabled TF32 for matrix operations\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.device\u001b[0m:\u001b[36msetup_cuda_optimizations\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCleared CUDA cache\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mNovel loss functions enabled\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1mCurriculum learning enabled\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mClinical validation enabled\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mCUBLAS error recovery enabled: 3 retries with 10s delay\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mHAQT-ARR enabled with regions: ['right_lung', 'left_lung', 'heart', 'mediastinum', 'spine', 'diaphragm', 'costophrenic_angles']\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mTrainer initialized on cuda\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1mTraining for 50 epochs\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mTotal optimization steps: 11966\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mLabel smoothing: 0.05\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mScheduled sampling: True (start=1.0, end=0.4)\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mRegion regularization: True (weight=0.01)\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:09.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m238\u001b[0m - \u001b[1mEarly stopping patience: 20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "XR2Text Training with AUTO-RESUME\n",
      "======================================================================\n",
      "\n",
      "Clearing GPU memory...\n",
      "GPU Memory - Allocated: 2.03 GB\n",
      "GPU Memory - Cached: 2.06 GB\n",
      "\n",
      ">>> CHECKPOINT FOUND: ..\\checkpoints\\best_model.pt\n",
      ">>> Resuming from epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:20:13.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m814\u001b[0m - \u001b[1mLoaded checkpoint from ..\\checkpoints\\best_model.pt\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:13.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m815\u001b[0m - \u001b[1mResuming from epoch 4\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:13.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mStarting training...\u001b[0m\n",
      "\u001b[32m2026-01-15 20:20:13.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36mprecompute_difficulty_scores\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mPre-computing difficulty scores for 30633 samples...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING CONFIGURATION SUMMARY:\n",
      "  Learning rate: 0.0001\n",
      "  Label smoothing: 0.05\n",
      "  Validate every: 2 epochs\n",
      "  Generation beams: 2\n",
      "  Min generation length: 20\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 20:23:20.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36mprecompute_difficulty_scores\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mPre-computed 30633 difficulty scores\u001b[0m\n",
      "\u001b[32m2026-01-15 20:23:20.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mCurriculum stage 'warmup': 3363/30633 samples\u001b[0m\n",
      "\u001b[32m2026-01-15 20:23:20.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mCurriculum stage: warmup (3363/30633 samples)\u001b[0m\n",
      "Epoch 5:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 26/27 [51:31<01:58, 118.89s/step, loss=8.6355]\n",
      "\u001b[32m2026-01-15 21:14:52.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mEpoch 5/50 | Train: 7.5560 | Val: SKIPPED (validating every 2 epochs)\u001b[0m\n",
      "\u001b[32m2026-01-15 21:14:59.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.logger\u001b[0m:\u001b[36mlog_checkpoint\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mCheckpoint saved: ..\\checkpoints\\checkpoint_epoch_5.pt (Epoch 5)\u001b[0m\n",
      "\u001b[32m2026-01-15 21:14:59.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mCurriculum stage 'easy': 9263/30633 samples\u001b[0m\n",
      "\u001b[32m2026-01-15 21:14:59.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mCurriculum stage: easy (9263/30633 samples)\u001b[0m\n",
      "Epoch 6:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 72/73 [2:31:17<02:06, 126.08s/step, loss=6.9927]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 306/306 [14:01<00:00,  2.75s/it]\n",
      "\u001b[32m2026-01-16 00:00:19.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.metrics\u001b[0m:\u001b[36mcompute_radgraph_f1\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mRadGraph not installed. Using simplified entity F1.\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:19.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m424\u001b[0m - \u001b[1mEpoch 6/50 | Train: 7.4194 | Val: 14.0577 | BLEU-4: 0.0048 | ROUGE-L: 0.1230\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:25.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.logger\u001b[0m:\u001b[36mlog_checkpoint\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mCheckpoint saved: ..\\checkpoints\\best_model.pt (Epoch 6, Metric: 0.1278)\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:25.375\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.utils.logger\u001b[0m:\u001b[36mlog_best_model\u001b[0m:\u001b[36m172\u001b[0m - \u001b[32m\u001b[1mNew best model at epoch 6! BLEU-4 + ROUGE-L: 0.1278\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:32.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.logger\u001b[0m:\u001b[36mlog_checkpoint\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mCheckpoint saved: ..\\checkpoints\\checkpoint_epoch_6.pt (Epoch 6)\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:32.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mCurriculum stage 'easy': 9263/30633 samples\u001b[0m\n",
      "\u001b[32m2026-01-16 00:00:32.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mCurriculum stage: easy (9263/30633 samples)\u001b[0m\n",
      "Epoch 7:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 72/73 [2:35:34<02:09, 129.65s/step, loss=8.1331]\n",
      "\u001b[32m2026-01-16 02:36:07.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mEpoch 7/50 | Train: 7.0048 | Val: SKIPPED (validating every 2 epochs)\u001b[0m\n",
      "\u001b[32m2026-01-16 02:36:16.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.logger\u001b[0m:\u001b[36mlog_checkpoint\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mCheckpoint saved: ..\\checkpoints\\checkpoint_epoch_7.pt (Epoch 7)\u001b[0m\n",
      "\u001b[32m2026-01-16 02:36:16.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.curriculum\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mCurriculum stage 'easy': 9263/30633 samples\u001b[0m\n",
      "\u001b[32m2026-01-16 02:36:16.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mCurriculum stage: easy (9263/30633 samples)\u001b[0m\n",
      "Epoch 8:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 62/73 [2:23:19<25:12, 137.51s/step, loss=6.8763]\u001b[32m2026-01-16 05:01:27.174\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.training.trainer\u001b[0m:\u001b[36m_train_epoch\u001b[0m:\u001b[36m585\u001b[0m - \u001b[33m\u001b[1mOOM at batch 8005, clearing cache and skipping (OOM count: 1)\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mF:\\MajorProject\\backend\\notebooks\\..\\src\\training\\trainer.py:520\u001b[0m, in \u001b[0;36mXR2TextTrainer._train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# First forward pass\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshifted_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Main loss (with label smoothing applied in model)\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\backend\\notebooks\\..\\src\\models\\xr2text.py:305\u001b[0m, in \u001b[0;36mXR2TextModel.forward\u001b[1;34m(self, images, decoder_input_ids, decoder_attention_mask, labels)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# Shape: (B, num_queries, language_dim)\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Step 3: Generate text with decoder\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojected_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m output \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: decoder_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: decoder_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: visual_features,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojected_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: projected_features,\n\u001b[0;32m    317\u001b[0m }\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\backend\\notebooks\\..\\src\\models\\biobart_decoder.py:282\u001b[0m, in \u001b[0;36mBioBARTDecoder.forward\u001b[1;34m(self, encoder_hidden_states, decoder_input_ids, decoder_attention_mask, labels, encoder_attention_mask, output_hidden_states)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_bart:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# IMPROVED: Get hidden states for cross-modal alignment loss\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't compute loss internally\u001b[39;49;00m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# IMPROVED: Enable hidden states\u001b[39;49;00m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# Compute loss with label smoothing\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1472\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1468\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1469\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1470\u001b[0m         )\n\u001b[1;32m-> 1472\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1491\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1289\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1122\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1122\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:435\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_values, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[0;32m    433\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 435\u001b[0m hidden_states, cross_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:219\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_values, attention_mask, layer_head_mask, output_attentions, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# get query proj\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mq_input_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    221\u001b[0m is_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m final_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Extract history from trainer for visualization\u001b[39;00m\n\u001b[0;32m     84\u001b[0m history \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: trainer\u001b[38;5;241m.\u001b[39mmetrics_tracker\u001b[38;5;241m.\u001b[39mget_history(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: trainer\u001b[38;5;241m.\u001b[39mmetrics_tracker\u001b[38;5;241m.\u001b[39mget_history(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [trainer\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m*\u001b[39m (trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     95\u001b[0m }\n",
      "File \u001b[1;32mF:\\MajorProject\\backend\\notebooks\\..\\src\\training\\trainer.py:413\u001b[0m, in \u001b[0;36mXR2TextTrainer.train\u001b[1;34m(self, start_epoch)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_scheduled_sampling_ratio(epoch)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Validation phase - configurable frequency (default every 2 epochs)\u001b[39;00m\n\u001b[0;32m    416\u001b[0m validate_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidate_every\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mF:\\MajorProject\\backend\\notebooks\\..\\src\\training\\trainer.py:587\u001b[0m, in \u001b[0;36mXR2TextTrainer._train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    585\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOOM at batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, clearing cache and skipping (OOM count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moom_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 587\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mF:\\MajorProject\\swin\\lib\\site-packages\\torch\\cuda\\memory.py:192\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Main training loop - Using XR2TextTrainer class\n",
    "# AUTO-RESUME: Automatically detects and resumes from best checkpoint\n",
    "from src.training.trainer import XR2TextTrainer\n",
    "import torch\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# AUTO-RESUME FROM CHECKPOINT\n",
    "# ============================================\n",
    "checkpoint_dir = Path(config['checkpoint_dir'])\n",
    "\n",
    "def find_best_checkpoint(checkpoint_dir):\n",
    "    \"\"\"Find the best checkpoint to resume from.\"\"\"\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    if not checkpoint_dir.exists():\n",
    "        return None, 0\n",
    "    \n",
    "    # Priority: best_model.pt > latest checkpoint_epoch_*.pt\n",
    "    best_model = checkpoint_dir / \"best_model.pt\"\n",
    "    if best_model.exists():\n",
    "        ckpt = torch.load(best_model, map_location='cpu')\n",
    "        return str(best_model), ckpt.get('epoch', 0) + 1\n",
    "    \n",
    "    # Find latest epoch checkpoint\n",
    "    epoch_checkpoints = list(checkpoint_dir.glob(\"checkpoint_epoch_*.pt\"))\n",
    "    if epoch_checkpoints:\n",
    "        # Sort by epoch number\n",
    "        def get_epoch(p):\n",
    "            try:\n",
    "                return int(p.stem.split('_')[-1])\n",
    "            except:\n",
    "                return 0\n",
    "        latest = max(epoch_checkpoints, key=get_epoch)\n",
    "        ckpt = torch.load(latest, map_location='cpu')\n",
    "        return str(latest), ckpt.get('epoch', 0) + 1\n",
    "    \n",
    "    return None, 0\n",
    "\n",
    "# Auto-detect checkpoint\n",
    "checkpoint_path, resume_epoch = find_best_checkpoint(checkpoint_dir)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"XR2Text Training with AUTO-RESUME\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Memory cleanup before training\n",
    "print(\"\\nClearing GPU memory...\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory - Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory - Cached: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "\n",
    "# Create trainer with optimized config\n",
    "trainer = XR2TextTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# AUTO-RESUME: Load checkpoint if found\n",
    "if checkpoint_path:\n",
    "    print(f\"\\n>>> CHECKPOINT FOUND: {checkpoint_path}\")\n",
    "    print(f\">>> Resuming from epoch {resume_epoch}\")\n",
    "    trainer.load_checkpoint(checkpoint_path)\n",
    "else:\n",
    "    print(\"\\n>>> No checkpoint found. Starting fresh training from epoch 1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING CONFIGURATION SUMMARY:\")\n",
    "print(f\"  Learning rate: {config['learning_rate']}\")\n",
    "print(f\"  Label smoothing: {config.get('label_smoothing', 0.1)}\")\n",
    "print(f\"  Validate every: {config.get('validate_every', 2)} epochs\")\n",
    "print(f\"  Generation beams: {config.get('generation', {}).get('num_beams', 5)}\")\n",
    "print(f\"  Min generation length: {config.get('generation', {}).get('min_length', 20)}\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# Run training\n",
    "final_metrics = trainer.train()\n",
    "\n",
    "# Extract history from trainer for visualization\n",
    "history = {\n",
    "    'train_loss': trainer.metrics_tracker.get_history('train_loss'),\n",
    "    'val_loss': trainer.metrics_tracker.get_history('val_loss'),\n",
    "    'bleu_1': trainer.metrics_tracker.get_history('bleu_1'),\n",
    "    'bleu_2': trainer.metrics_tracker.get_history('bleu_2'),\n",
    "    'bleu_3': trainer.metrics_tracker.get_history('bleu_3'),\n",
    "    'bleu_4': trainer.metrics_tracker.get_history('bleu_4'),\n",
    "    'rouge_1': trainer.metrics_tracker.get_history('rouge_1'),\n",
    "    'rouge_2': trainer.metrics_tracker.get_history('rouge_2'),\n",
    "    'rouge_l': trainer.metrics_tracker.get_history('rouge_l'),\n",
    "    'learning_rate': [trainer.scheduler.get_last_lr()[0]] * (trainer.current_epoch + 1),\n",
    "}\n",
    "\n",
    "# Add clinical validation metrics if enabled\n",
    "if config.get('use_clinical_validation', False):\n",
    "    history['clinical_accuracy'] = trainer.metrics_tracker.get_history('clinical_accuracy')\n",
    "    history['clinical_f1'] = trainer.metrics_tracker.get_history('clinical_f1')\n",
    "    history['critical_errors'] = trainer.metrics_tracker.get_history('critical_errors')\n",
    "\n",
    "# Save training history\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df['epoch'] = range(1, len(history_df) + 1)\n",
    "os.makedirs('../data/statistics', exist_ok=True)\n",
    "history_df.to_csv('../data/statistics/training_history.csv', index=False)\n",
    "\n",
    "# Store predictions and references for sample display\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nFinal Metrics:\")\n",
    "for key, value in final_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Final memory cleanup\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"\\nFinal GPU Memory - Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBUST FIX - handles any array length mismatch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get all the metrics\n",
    "val_loss = trainer.metrics_tracker.get_history('val_loss')\n",
    "bleu_1 = trainer.metrics_tracker.get_history('bleu_1')\n",
    "bleu_2 = trainer.metrics_tracker.get_history('bleu_2')\n",
    "bleu_3 = trainer.metrics_tracker.get_history('bleu_3')\n",
    "bleu_4 = trainer.metrics_tracker.get_history('bleu_4')\n",
    "rouge_1 = trainer.metrics_tracker.get_history('rouge_1')\n",
    "rouge_2 = trainer.metrics_tracker.get_history('rouge_2')\n",
    "rouge_l = trainer.metrics_tracker.get_history('rouge_l')\n",
    "train_loss = trainer.metrics_tracker.get_history('train_loss')\n",
    "\n",
    "# Debug: Print lengths\n",
    "print(\"Array lengths:\")\n",
    "print(f\"  val_loss: {len(val_loss)}\")\n",
    "print(f\"  bleu_4: {len(bleu_4)}\")\n",
    "print(f\"  rouge_l: {len(rouge_l)}\")\n",
    "print(f\"  train_loss: {len(train_loss)}\")\n",
    "\n",
    "# Find minimum length among validation metrics\n",
    "min_len = min(len(val_loss), len(bleu_4), len(rouge_l))\n",
    "print(f\"\\nUsing {min_len} epochs\")\n",
    "\n",
    "# Create DataFrame with matching lengths\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': list(range(2, 2 + min_len * 2, 2))[:min_len],\n",
    "    'val_loss': val_loss[:min_len],\n",
    "    'bleu_1': bleu_1[:min_len],\n",
    "    'bleu_2': bleu_2[:min_len],\n",
    "    'bleu_3': bleu_3[:min_len],\n",
    "    'bleu_4': bleu_4[:min_len],\n",
    "    'rouge_1': rouge_1[:min_len],\n",
    "    'rouge_2': rouge_2[:min_len],\n",
    "    'rouge_l': rouge_l[:min_len],\n",
    "})\n",
    "\n",
    "# Add train_loss if available (sample every 2nd)\n",
    "if train_loss:\n",
    "    sampled_train = train_loss[1::2][:min_len]\n",
    "    if len(sampled_train) == min_len:\n",
    "        history_df['train_loss'] = sampled_train\n",
    "\n",
    "# Save\n",
    "os.makedirs('../data/statistics', exist_ok=True)\n",
    "history_df.to_csv('../data/statistics/training_history.csv', index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(history_df)} epochs!\")\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(history_df.tail())\n",
    "print(f\"\\nBest BLEU-4: {history_df['bleu_4'].max():.4f}\")\n",
    "print(f\"Best ROUGE-L: {history_df['rouge_l'].max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Curves Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 NOVEL: Enhanced Curriculum Learning Analysis\n",
    "\n",
    "This section provides detailed analysis of our curriculum learning strategy,\n",
    "showing how it affects training dynamics and final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# NOVEL: ENHANCED CURRICULUM LEARNING ANALYSIS (5 STAGES, 50 EPOCHS)\n",
    "# ============================================\n",
    "from src.training.curriculum import AnatomicalCurriculumScheduler\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NOVEL: CURRICULUM LEARNING ANALYSIS (5 STAGES, 50 EPOCHS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize curriculum scheduler\n",
    "curriculum = AnatomicalCurriculumScheduler()\n",
    "\n",
    "# Display curriculum stages\n",
    "print(\"\\n1. CURRICULUM STAGES (5-Stage Progressive Training)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\n{'Stage':<20} {'Epochs':<15} {'Description':<40}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "stage_descriptions = {\n",
    "    'warmup': 'Warmup with easy cases only',\n",
    "    'easy': 'Normal X-rays, simple findings',\n",
    "    'medium': 'Single anatomical region findings',\n",
    "    'hard': 'Multiple regions, moderate complexity',\n",
    "    'finetune': 'Complex cases, full dataset fine-tuning',\n",
    "}\n",
    "\n",
    "for stage in curriculum.stages:\n",
    "    name = stage['name']\n",
    "    epoch_range = f\"{stage['epoch_start']}-{stage['epoch_end']}\"\n",
    "    desc = stage_descriptions.get(name, 'Full dataset')\n",
    "    print(f\"{name:<20} {epoch_range:<15} {desc:<40}\")\n",
    "\n",
    "# Sample difficulty scoring demo\n",
    "print(\"\\n2. SAMPLE DIFFICULTY SCORING\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "sample_reports = [\n",
    "    \"Lungs are clear. Heart size is normal. No acute cardiopulmonary process.\",\n",
    "    \"Mild cardiomegaly. Lungs are clear bilaterally.\",\n",
    "    \"Bilateral pleural effusions. Cardiomegaly. Pulmonary edema.\",\n",
    "    \"Large right pneumothorax. Left lung consolidation. Cardiomegaly.\",\n",
    "]\n",
    "\n",
    "print(\"\\nSample Reports with Difficulty Scores:\")\n",
    "for i, report in enumerate(sample_reports):\n",
    "    scores = curriculum.difficulty_scorer(report)\n",
    "    total_difficulty = scores.get('num_findings', 0) + scores.get('severity_score', 0)\n",
    "    print(f\"\\n[Sample {i+1}] Difficulty: {total_difficulty:.1f}\")\n",
    "    print(f\"   Report: {report[:60]}...\")\n",
    "    print(f\"   Findings: {scores.get('num_findings', 0)}, Regions: {scores.get('num_regions', 0)}\")\n",
    "\n",
    "# Load and analyze training history\n",
    "print(\"\\n3. CURRICULUM LEARNING IMPACT\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history_path = '../data/statistics/training_history.csv'\n",
    "if os.path.exists(history_path):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CURRICULUM LEARNING RESULTS (Real Data)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df = pd.read_csv(history_path)\n",
    "\n",
    "    print(\"\\nPerformance at Curriculum Stage Transitions:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # 5-stage curriculum for 50 epochs: warmup(0-5), easy(5-12), medium(12-25), hard(25-40), finetune(40-50)\n",
    "    stage_info = [\n",
    "        (5, 'End of Stage 1 (Warmup)'),\n",
    "        (12, 'End of Stage 2 (Easy Cases)'),\n",
    "        (25, 'End of Stage 3 (Medium Cases)'),\n",
    "        (40, 'End of Stage 4 (Hard Cases)'),\n",
    "        (50, 'End of Stage 5 (Fine-tuning)'),\n",
    "    ]\n",
    "\n",
    "    for target_epoch, stage_name in stage_info:\n",
    "        mask = df['epoch'] <= target_epoch\n",
    "        if mask.any():\n",
    "            row = df[mask].iloc[-1]\n",
    "            print(f\"\\nEpoch {int(row['epoch'])} - {stage_name}:\")\n",
    "            print(f\"  BLEU-4:  {row['bleu_4']:.4f}\")\n",
    "            print(f\"  ROUGE-L: {row['rouge_l']:.4f}\")\n",
    "            print(f\"  Val Loss: {row['val_loss']:.4f}\")\n",
    "\n",
    "    # Plot curriculum impact\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Stage transitions at epochs 5, 12, 25, 40\n",
    "    stage_transitions = [5, 12, 25, 40]\n",
    "\n",
    "    # BLEU-4 progression with stage markers\n",
    "    axes[0].plot(df['epoch'], df['bleu_4'], linewidth=2, color='blue', marker='o', markersize=3)\n",
    "    for trans in stage_transitions:\n",
    "        axes[0].axvline(x=trans, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('BLEU-4')\n",
    "    axes[0].set_title('BLEU-4 Progression with 5-Stage Curriculum')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss progression with stage markers\n",
    "    axes[1].plot(df['epoch'], df['val_loss'], linewidth=2, color='orange', marker='o', markersize=3)\n",
    "    for trans in stage_transitions:\n",
    "        axes[1].axvline(x=trans, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Validation Loss')\n",
    "    axes[1].set_title('Loss Progression with 5-Stage Curriculum')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('../data/figures', exist_ok=True)\n",
    "    plt.savefig('../data/figures/curriculum_impact.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Curriculum learning analysis complete!\")\n",
    "    print(\"Figure saved: ../data/figures/curriculum_impact.png\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\nTraining history not found yet.\")\n",
    "    print(\"Run this cell again after training completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FIXED: TRAINING CURVES VISUALIZATION\n",
    "# ============================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load history from CSV\n",
    "history_path = \"../data/statistics/training_history.csv\"\n",
    "\n",
    "if os.path.exists(history_path):\n",
    "    print(\"Loading training history from CSV...\")\n",
    "    df = pd.read_csv(history_path)\n",
    "    print(f\"Loaded {len(df)} epochs of data\")\n",
    "\n",
    "    # Check if we have data\n",
    "    if len(df) > 0 and 'bleu_4' in df.columns:\n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Plot 1: Validation Loss\n",
    "        axes[0].plot(df['epoch'], df['val_loss'], label='Val Loss', color='orange', linewidth=2, marker='o', markersize=4)\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Validation Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: BLEU Scores\n",
    "        axes[1].plot(df['epoch'], df['bleu_1'], label='BLEU-1', linewidth=2)\n",
    "        axes[1].plot(df['epoch'], df['bleu_2'], label='BLEU-2', linewidth=2)\n",
    "        axes[1].plot(df['epoch'], df['bleu_3'], label='BLEU-3', linewidth=2)\n",
    "        axes[1].plot(df['epoch'], df['bleu_4'], label='BLEU-4', linewidth=2, marker='o', markersize=4)\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Score')\n",
    "        axes[1].set_title('BLEU Scores')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 3: ROUGE Scores\n",
    "        axes[2].plot(df['epoch'], df['rouge_1'], label='ROUGE-1', linewidth=2)\n",
    "        axes[2].plot(df['epoch'], df['rouge_2'], label='ROUGE-2', linewidth=2)\n",
    "        axes[2].plot(df['epoch'], df['rouge_l'], label='ROUGE-L', linewidth=2, marker='o', markersize=4)\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Score')\n",
    "        axes[2].set_title('ROUGE Scores')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 4: Combined BLEU-4 and ROUGE-L\n",
    "        axes[3].plot(df['epoch'], df['bleu_4'], label='BLEU-4', linewidth=2, color='blue', marker='o', markersize=4)\n",
    "        axes[3].plot(df['epoch'], df['rouge_l'], label='ROUGE-L', linewidth=2, color='green', marker='s', markersize=4)\n",
    "        axes[3].set_xlabel('Epoch')\n",
    "        axes[3].set_ylabel('Score')\n",
    "        axes[3].set_title('BLEU-4 vs ROUGE-L Comparison')\n",
    "        axes[3].legend()\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs('../data/figures', exist_ok=True)\n",
    "        plt.savefig('../data/figures/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nTraining curves saved to ../data/figures/training_curves.png\")\n",
    "\n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"TRAINING SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Best BLEU-4:  {df['bleu_4'].max():.4f} (Epoch {df.loc[df['bleu_4'].idxmax(), 'epoch']:.0f})\")\n",
    "        print(f\"Best ROUGE-L: {df['rouge_l'].max():.4f} (Epoch {df.loc[df['rouge_l'].idxmax(), 'epoch']:.0f})\")\n",
    "        print(f\"Final Val Loss: {df['val_loss'].iloc[-1]:.4f}\")\n",
    "    else:\n",
    "        print(\"No valid data in CSV file\")\n",
    "else:\n",
    "    print(\"Training history CSV not found!\")\n",
    "    print(\"Expected at:\", history_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions vs ground truth\n",
    "print(\"Sample Predictions vs Ground Truth:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if predictions and references exist\n",
    "if 'predictions' not in dir() or not predictions:\n",
    "    predictions = []\n",
    "if 'references' not in dir() or not references:\n",
    "    references = []\n",
    "\n",
    "if len(predictions) > 0 and len(references) > 0:\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"\\nGround Truth:\")\n",
    "        print(references[i][:500] + \"...\" if len(references[i]) > 500 else references[i])\n",
    "        print(f\"\\nGenerated:\")\n",
    "        print(predictions[i][:500] + \"...\" if len(predictions[i]) > 500 else predictions[i])\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"\\n⚠️ No predictions available yet!\")\n",
    "    print(\"   Predictions will be available after training completes (cell 11).\")\n",
    "    print(\"   Or run evaluation on test set in notebook 03_evaluation.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FIXED: FINAL RESULTS SUMMARY\n",
    "# ============================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "history_path = \"../data/statistics/training_history.csv\"\n",
    "\n",
    "if os.path.exists(history_path):\n",
    "    df = pd.read_csv(history_path)\n",
    "\n",
    "    # Find best epoch by combined BLEU-4 + ROUGE-L score\n",
    "    df['combined_score'] = df['bleu_4'] + df['rouge_l']\n",
    "    best_idx = df['combined_score'].idxmax()\n",
    "    best_row = df.loc[best_idx]\n",
    "    final_row = df.iloc[-1]\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TRAINING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # FIXED: Use actual epoch value from the dataframe\n",
    "    print(f\"\\nBest Epoch: {int(best_row['epoch'])} (by BLEU-4 + ROUGE-L)\")\n",
    "\n",
    "    print(f\"\\nBest Metrics (Epoch {int(best_row['epoch'])}):\")\n",
    "    print(f\"  BLEU-1:  {best_row['bleu_1']:.4f}\")\n",
    "    print(f\"  BLEU-2:  {best_row['bleu_2']:.4f}\")\n",
    "    print(f\"  BLEU-3:  {best_row['bleu_3']:.4f}\")\n",
    "    print(f\"  BLEU-4:  {best_row['bleu_4']:.4f}\")\n",
    "    print(f\"  ROUGE-1: {best_row['rouge_1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {best_row['rouge_2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {best_row['rouge_l']:.4f}\")\n",
    "\n",
    "    print(f\"\\nFinal Metrics (Epoch {int(final_row['epoch'])}):\")\n",
    "    print(f\"  Val Loss: {final_row['val_loss']:.4f}\")\n",
    "    print(f\"  BLEU-4:   {final_row['bleu_4']:.4f}\")\n",
    "    print(f\"  ROUGE-L:  {final_row['rouge_l']:.4f}\")\n",
    "\n",
    "    # Save best results to CSV\n",
    "    results_table = pd.DataFrame({\n",
    "        'Metric': ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
    "        'Best Score': [\n",
    "            best_row['bleu_1'],\n",
    "            best_row['bleu_2'],\n",
    "            best_row['bleu_3'],\n",
    "            best_row['bleu_4'],\n",
    "            best_row['rouge_1'],\n",
    "            best_row['rouge_2'],\n",
    "            best_row['rouge_l'],\n",
    "        ],\n",
    "        'Final Score': [\n",
    "            final_row['bleu_1'],\n",
    "            final_row['bleu_2'],\n",
    "            final_row['bleu_3'],\n",
    "            final_row['bleu_4'],\n",
    "            final_row['rouge_1'],\n",
    "            final_row['rouge_2'],\n",
    "            final_row['rouge_l'],\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    os.makedirs('../data/statistics', exist_ok=True)\n",
    "    results_table.to_csv('../data/statistics/best_results.csv', index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Results saved to ../data/statistics/best_results.csv\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Display table\n",
    "    print(\"\\nResults Table:\")\n",
    "    print(results_table.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TRAINING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nNo training results available yet!\")\n",
    "    print(\"Run training first (cell 11) to see results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. NOVEL: Enhanced Analysis with New Features\n",
    "\n",
    "##This section demonstrates the new enhancement modules for comprehensive report analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# NOVEL: Enhanced Analysis Demo\n",
    "# ============================================\n",
    "# This demonstrates the new enhancement modules\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NOVEL ENHANCEMENT MODULES DEMO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if model has enhancement modules\n",
    "if hasattr(model, 'generate_with_analysis'):\n",
    "    print(\"\\n✅ Model has enhanced analysis capabilities!\")\n",
    "    print(\"\\nAvailable analysis features:\")\n",
    "    print(\"  1. Uncertainty Quantification\")\n",
    "    print(\"     - Overall confidence score (0-1)\")\n",
    "    print(\"     - Per-finding confidence scores\")\n",
    "    print(\"     - Calibrated uncertainty estimates\")\n",
    "    print(\"\\n  2. Factual Grounding\")\n",
    "    print(\"     - Detected medical findings\")\n",
    "    print(\"     - Potential hallucinations flagged\")\n",
    "    print(\"     - Knowledge graph validation\")\n",
    "    print(\"\\n  3. Explainability\")\n",
    "    print(\"     - Evidence regions highlighted\")\n",
    "    print(\"     - Clinical reasoning chains\")\n",
    "    print(\"     - Attention visualizations\")\n",
    "    print(\"\\n  4. Multi-Task Outputs\")\n",
    "    print(\"     - Region classification\")\n",
    "    print(\"     - Severity prediction\")\n",
    "    print(\"     - Finding detection\")\n",
    "    \n",
    "    # Demo analysis on a sample if test data is available\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"Running Enhanced Analysis on Sample...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get a sample from test loader\n",
    "        sample_batch = next(iter(test_loader))\n",
    "        sample_image = sample_batch['images'][0:1].to(config['device'])\n",
    "        \n",
    "        # Run enhanced analysis\n",
    "        with torch.no_grad():\n",
    "            analysis = model.generate_with_analysis(\n",
    "                sample_image,\n",
    "                max_length=config['generation']['max_length'],\n",
    "                num_beams=config['generation']['num_beams'],\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n📝 Generated Report:\")\n",
    "        print(f\"   {analysis.get('report', 'N/A')[:200]}...\")\n",
    "        \n",
    "        print(f\"\\n📊 Uncertainty Analysis:\")\n",
    "        print(f\"   Overall Confidence: {analysis.get('confidence', 0):.2%}\")\n",
    "        if 'finding_confidences' in analysis:\n",
    "            print(f\"   Finding Confidences: {len(analysis['finding_confidences'])} findings analyzed\")\n",
    "        \n",
    "        print(f\"\\n🔍 Factual Grounding:\")\n",
    "        if 'detected_findings' in analysis:\n",
    "            print(f\"   Detected Findings: {analysis['detected_findings'][:5]}\")\n",
    "        if 'potential_hallucinations' in analysis:\n",
    "            print(f\"   Potential Hallucinations: {len(analysis.get('potential_hallucinations', []))}\")\n",
    "        \n",
    "        print(f\"\\n💡 Explainability:\")\n",
    "        if 'evidence_regions' in analysis:\n",
    "            print(f\"   Evidence Regions: {len(analysis['evidence_regions'])} regions identified\")\n",
    "        if 'reasoning' in analysis:\n",
    "            print(f\"   Clinical Reasoning: Available\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Demo skipped (requires trained model): {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n⚠️  Enhancement modules not loaded in current model.\")\n",
    "    print(\"   Ensure use_uncertainty, use_grounding, use_explainability, use_multitask are True.\")\n",
    "    print(\"   Re-initialize model with updated config to enable these features.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Enhanced Analysis Demo Complete\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (swin)",
   "language": "python",
   "name": "swin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
